---
title: CS 231n Note7 笔记
date: 2024-10-26 21:00
tags:
    - 梯度检查
    - 损失函数
    - 参数更新算法
    - 动量法
    - 超参数调优
    - 集成模型
categories: 机器学习笔记
mathjax: true
---

<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']],

			displayMath: [['$$', '$$']]

            }
        });
    </script>
</head>

这节将会学习在模型训练的过程中将要做的一些事
## Gradient Check
之前我们提到，为了模型训练的高效，我们需要以解析的方式计算梯度，然而这样是很有可能会出错的，于是我们需要在训练过程中使用梯度检查确保我们的解析梯度计算没有出错，一下是需要注意的点：
**使用中心差分公式**
为了使数值梯度计算更加准确，我们不能朴素地计算数值梯度，而应采用中心差分公式：
$$\frac{f(x+h) - f(x-h)}{2h}\approx \frac{\partial f}{\partial x}$$
实际上，采用泰勒公式进行估算即可发现中心差分公式的误差在$O(h^2)$而朴素的计算在$O(h)$。
**在比较时使用相对误差**
如标题，应该不需要解释，这是显然的，这里贴一下公式：
$$\delta = \frac{|f_a' - f_n'|}{\max(f_a', f_n')}$$

此外，我们一般期望相对误差小于$1e-7$，在$1e-7$到$1e-4$之间的值可能是使用差分公式的时候跨越了不连续点，在这以上的值都是不正常的。
需要注意的是，神经网络的深度也会极大地影响相对误差的大小，因此在一个十层以上的网络中出现了$1e-2$大小的误差也许也是正常的。
**使用更高精度的浮点数**
这也是显然的，为了提高误差的精度。
**将参与计算的浮点数数值保持在一个合适的范围内**
在神经网络中，对于损失函数值进行标准化是一种常见的行为，然而这会损失浮点数的精度。因此我们需要在计算时尽量使用原始数据，并且不要让参与计算的浮点数过小（例如小于$1e-10$），如果浮点数真的过小，那么我们可以暂时的放大它们以获得更高的精度。
**目标函数中的非连续点**
例如我们将会使用的激活函数$ReLU$或是SVM损失函数，它们的图像上都含有不连续点，而当我们需要计算梯度的点很靠近不连续点时，就会引入很大的误差（例如在$ReLU$函数$x=1e-6$处采用$h = 1e-5$，就会计算出一个非零的梯度，而实际应该是0）。
并且，由于我们需要处理的数据量一般很大，这个问题是十分常见的。一个解决办法就是在计算的过程中追踪$\max$函数中"胜出"的值是否发生改变，即计算当$x$分别等于$x+h$和$x-h$时，在$\max$函数中胜出的值是否发生改变
**不必对所有数据都进行检查**
如题，只需从数据中选取一些点进行梯度检查。
**小心选取步长$h$**
值得一提的是，步长$h$并非越小越好，详见笔记中的一篇文章详述了如何选取合适的$h$。
**在学习过程的"典型"阶段进行检查**
需要注意的是，我们只是对学习过程中一个特定时间点的特定数据进行检查，检查通过并不意味着实现正确，实际上，检查正确可能只是特殊情况，不具有普遍性。
因此在开始阶段进行检查时不明智的，因为开始阶段本身就是一个极其特殊的阶段，一般我们会在损失函数开始下降的时候进行梯度检查。
**不要让正则化损失盖过数据**
一般我们的损失函数由数据损失与正则化损失两部分构成，如果我们将正则化强度设置太高，可能会导致梯度主要来源于正则化损失，从而无法正确地检查数据损失梯度的计算。
因此，正确的做法是分别检查正则化损失以及数据损失的梯度。检查数据损失时，我们采用将正则化强度设置为0的方法，检查正则化损失时，我们一般会修改代码或者让正则化强度变成一个很大的值。
**检查时停止使用dropout/数据增强**
这是很显然的，在这种很需要精度的时候应当排除所有随机化因素的影响。
当然，为了一同检查dropout的实现是否有误，我们可以在不关闭dropout的前提下，用固定的随机种子进行测试。
**检查少数几个数据维度**
注意，我们需要为每个参数随机选取几个维度进行测试，然而，为了确保所有参数都能被检查到，随机选择的方式也需要注意。

## Before learning: sanity checks Tips/Tricks
在训练之前，我们也可以通过一些手段检查某些设置是否正确。
**计算随机情况下的期望梯度与实际梯度相比是否合理**
如题，以Softmax分类器为例，如果分类器有十个类别，那么在随机情况下的初始化随机梯度应该为$-\log \frac{1}{10} = 2.302$。
同时，对于有十个类别的SVM分类器，那么它的期望损失函数应该为$9\Delta$。
**增加正则化强度应该使损失函数上升**
**尝试过拟合一个很小的训练集**
在正式训练之前，我们可以将正则化强度设置为0，并且训练一个很小的训练集，并观察模型在这个训练集上能否达到0损失函数的效果。
注意，能达到0也并不意味着模型是正确的。

## Babysitting the learning process
在训练的过程中，我们需要监视几个训练过程中的重要变量以观察训练是否正常进行。
其中，如果我们采用mini-batch的训练方法，我们最好监视每个样本被选取的次数而不是训练迭代的次数。
### Loss Function
![](/assets/CS-231n-6/1.png)
首先需要监视的就是损失函数的变化趋势，一个好的学习率应该导出一个快速收敛到较低值的曲线。
![](/assets/CS-231n-6/2.png)
同时，损失函数的值可能还会出现波动的情况，这一般会出现在mini-batch训练的过程中。这是由于我们每次只选取一小部分训练数值，从而导致对整体的损失函数值并未下降。批次大小越小，波动往往越大，同时若不采用批次训练，理论上不应该出现波动。
此外，我们也可以将y轴化为对数坐标，这样较优的损失函数曲线应该是一条直线。
我们还可以在一张图赏画出多个交叉验证的曲线。
### Train/Val Accuracy
我们还需要监视模型对Train/Validation Set的准确率变化。
这不仅是为了监视模型训练的进度，还可以反映出模型是否存在过拟合的现象。
![](/assets/CS-231n-6/3.png)
如上图，若对Training Set的准确率显著地高于对Validation Set的准确率，则可以看出模型已经有很强的过拟合了。

### Ratio of weights:updates
即更新幅度与权重的比值：
```python
param_scale = np.linalg.norm(W.ravel())
update = - learning_rate* dW # simple SGD update
update_scale = np.linalg.norm(update.ravel())
W + = update # the actual update
p r i n t update_scale / param_scale # want ~1e-3
```
其实也就是计算
$$\frac{||lr*dW||_2}{||W||_2}$$
一种启发式方法指出，这个的值应该在$1e-3$左右，若太低就应当提高学习率，否则降低学习率。

### Activation / Gradient distributions per layer
还可以对每层神经元绘制激活值/梯度的分布图。
一个合适的层应当使神经元均匀的分布在值域之中而非出现某些值附近聚集了很多神经元的情况。

### First-layer Visualizations
在图像进过第一层神经元提取过特征值后，我们可以将它们绘制出来并评估。
![](/assets/CS-231n-6/4.png)
如上，第一章图具有很多噪点，因而不好。较好的实现应当呈现第二种的特征：平滑干净，具有广泛的特征

## Parameter Updates
由于训练资源限制，如何优化参数的更新也是一个重要的研究方向，不恰当的更新方式可能使得模型收敛极为缓慢或者收敛到错误的值。
### Vanilla Update
不解释，这是朴素更新方式：
```python
x += -learning_rate * dx
```
### Momentum update
这是一种模拟物理的方法，代码为：
```python
# Momentum update
v = mu * v - learning_rate * dx # integrate velocity
x + = v # integrate position
```
我们维护一个速度，每次更新时速度衰减并且增加一个朝这次更新所计算出梯度方向的速度，最后再根据速度更新位置。
这样如果梯度一直朝一个方向，那么模型就可以快速收敛。
`mu`是一个超参数，控制速度减少的速率，这也使得模型能在到达"谷底"时能够停下来。
### Nesterov Momentum
这是一种动量法的变体，注意到在动量法中不管怎么样位置都会进行一次$v_ * mu$的变化，于是在这种方法中我们不在维护当前位置而维护$x\_ahead = x + v * mu$的值：
$$\begin{aligned}
& x\_ahead = x + v\_prev*mu\\
&v = mu*v\_prev -lr*dx\_ahead\\
&x\_new = x - v\_prev*mu+v\\
&x\_newahead = x\_new +mu*v
\end{aligned}$$
代码：
```python
# Nesterov Momentum
v_prev = v # back this up
v = mu * v - learning_rate * dx # velocity update stays the same
x + = - mu * v_prev + (1 + mu) * v # position update changes form
```

### Annealing the learning rate
在训练过程中不断减少学习率是一种常用且必要的技巧，这是因为若是学习率不逐步减小，那权重就会在"曲面"上反弹不定而难以收敛到最低点。然而如何调整退货速度是一个问题，下面是几种策略：
**Step Decay**
这是一种很朴素的做法，即为每隔几个周期就将学习率以一定幅度降低。此外，还有一种启发式方式：当Validation准确率不再上升时就开始衰减学习率
**Exponential decay**
见公式，其中$t$时迭代次数，$k$是超参数：
$$\alpha = \alpha_0e^{-kt}$$
**1/t decay**
$$\alpha = \frac{\alpha_0}{1+kt}$$
### Second order methods
这是一种基于牛顿法的梯度更新方法，它不需要任何的超参数，更新公式如下：
$$x\leftarrow x - [H(x)]^{-1}\nabla f(x)$$
其中$H(x)$是Hessian矩阵，形如：
$$\begin{bmatrix}
\frac{\partial f}{\partial x_1\partial x_1} & \frac{\partial f}{\partial x_1\partial x_2} & ... &\frac{\partial f}{\partial x_1\partial x_n}\\
\frac{\partial f}{\partial x_2\partial x_1} & \frac{\partial f}{\partial x_2\partial x_2} & ... &\frac{\partial f}{\partial x_2\partial x_n}\\
...& ...&...&...\\
\frac{\partial f}{\partial x_n\partial x_1}&\frac{\partial f}{\partial x_n\partial x_2}&...&\frac{\partial f}{\partial x_n\partial x_n}
\end{bmatrix}$$
然而因为计算Hassian矩阵需要使用$\Theta(n^2)$的空间，过于消耗资源，而很少被使用。尽管有类似L-BFGS的优化空间的算法，但还是因为每次更新都需要计算整个训练集而不能使用小批训练，不被广泛使用。

### Per-parameter adaptive learning rate methods
之前的方法都是对所有参数全局地设置学习率，现在我们要介绍一些对每个参数自适应地设置学习率的方法。
不想翻译解释了，下面之间放代码，都很好理解，主体思想都是通过记录更新大小的累积值，让更新频繁的维度学习率下降，更新稀疏的维度学习率上升。第二个方法缓解了第一个方法学习率严格单减的缺点，第三个方法融合了动量方法：

**Adagrad**
```python
# Assume the gradient dx and parameter vector x
cache + = dx**2
x + = - learning_rate * dx / (np.sqrt(cache) + eps)
```

**RMSprop**
```python
# RMSprop
cache = decay_rate * cache + (1 - decay_rate) * dx**2
x + = - learning_rate * dx / (np.sqrt(cache) + eps)
```

**Adam**
```python
# Adam
m = beta1* m + (1- beta1)* dx
v = beta2* v + (1- beta2)* (dx**2)
x + = - learning_rate * m / (np.sqrt(v) + eps)
```

### Hyperparameter optimization
实际上，不只是学习率，有很多的超参数都需要我们寻找并优化，比如正则化强度等。

**Implementation**
我们一般会采用工作线程从空间中采样可能的超参数取值并记录随时间变化的模型的各项数据（在一个共享的文件系统中写入文件）。并且额外使用一个主线程管理工作线程，还可以检查各种记录。

**Prefer one validation fold to cross-validation**
如题，尝试超参数时一般使用单一验证而非交叉验证，这是为了提高效率。

**Hyperparameter ranges**
需要注意超参数取值的范围，对于在训练过程中具有乘法效果的超参数（如学习率，正则化强度），我们一般采用对数取值：`hp = 10 ** uniform(-6, -2)`。
但是对于dropout关闭率这样的超参数，我们还是应当使用均匀的普通取值。

**Prefer random search to grid search**
我也不知道他想说什么，反正全部随机就完了。

**Careful with best values on border**
如果最佳值在边界上出现，需要注意是否是取值范围选取有误。

**Stage your search from coarse to fine**
我们一般会在一个大的范围上进行一次周期训练，在从中选取较优的范围进行多次周期训练。这是因为在范围较大时，很多参数组合甚至不能正常完成训练。

**Bayesian Hyperparameter Optimization**
前沿领域，对本课内容无帮助，有兴趣可以了解。

## Evaluation: Model Ensembles
在实际中，我们经常会同时训练数个独立的模型，并在推理时将它们的输出平均，集成得到结果。在这个技术中，我们希望我们训练的多个模型具有较高的多样性，因为这样有更好的效果。
下面是一些做法：

**Same model, different initializations**
如题，用不同的权重初始值，但这样模型的多样性仅来源于初始值的不同。

**Top models discovered during cross-validation**
使⽤交叉验证确定超参数并选⽤其中表现最好的数个模型，尽管这样会大幅提高模型多样性，但这样有可能会包括非最优模型的隐患。

**Different checkpoints of a single model**
即使用模型在训练过程中的不同阶段，缺点就是多样性不高，但这样做只需极低的成本。

**Running average of parameters during training**
维护使用指数衰减平均的权重拷贝。尽管这看上去没什么道理，但使用中确实可以提升$1-2\%$的性能。

还需要注意的是，使用集成模型会提高推理的资源消耗，这是它的一大缺点。