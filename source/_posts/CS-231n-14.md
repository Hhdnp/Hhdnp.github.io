---
title: CS 231n Lec12 笔记
date: 2024-11-30 14:00
tags:
    - 自监督学习
    - Self-Supervised Learning
    - Pretext Task
    - Contrastive Representation Learning
    - Sequence Contrastive Learning
categories: 机器学习笔记
mathjax: true
---

<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']],

			displayMath: [['$$', '$$']]

            }
        });
    </script>
</head>

## Self-Supervised Learning
对于之前介绍的所有网络，在需要大规模训练时都存在一个问题，即需要使用大量的带有标签的数据（实际上这是一项很繁琐的工作）。从而我们设想，能否摆脱对大量标签数据的依赖？
一种解决方案就是自监督学习（Self-Supervised Learning），自监督学习的过程一般分为两部分：
1. Pretext Task 预任务
在这一步中，我们使用大量不带有标签的数据以一特定的不需要标签的任务为目标进行训练。这一阶段的训练可以被视作是无监督学习（Unsupervised Learning）。但在自监督学习中我们的最终目标与有监督学习一致(如分类，回归等等)。
2. DownStream Task 下游任务
这一部分是自监督学习实际上的下游应用，在这一部分中，我们使用少量带有标签的数据对模型进行微调训练使之能够更好地进行专门的任务。
![](/assets/CS-231n-14/Pasted image 20241129200658.png)
![](/assets/CS-231n-14/Pasted image 20241129200711.png)

其中预任务有以下作用：
1. 使模型在训练预任务时能够学习到发掘特征的能力，并且在预任务中训练出的特征提取能力通常来说是相对泛化的，具有良好的可迁移性，可以很好地被直接用于下游任务。
2. 预任务训练过程中模型实际上也能自动生成标签（伪标签）

### How to Evaluate a Self-Supervised Learning Method
我们可以按以下标准评估自监督学习方法：
1. 模型在预任务中的表现
2. 评估模型在预任务训练中学习到的表征提取能力（可通过Linear Evaluation Protocol, Clustering, t-NSE等方法）
3. 评估模型的鲁棒性和泛化能力
4. 评估预任务训练的训练效率
5. 评估经过预任务训练模型的迁移能力和在下游任务中的表现
![](/assets/CS-231n-14/Pasted image 20241129201106.png)

## Pretext Task from Image Transformation
### Pretext Task: Predict Rotations
我们可以将模型预测一张图片被旋转的角度来使模型具有特征提取的能力，这基于这样的一个假设：
当一个模型具有辨别图像被旋转的正确角度的时候，我们可以认为模型对于一般物体正常来说应当是什么样的有了基础的"视觉常识"。

这种训练的方式也很简单，将一张图分别旋转$0^{\circ},90^{\circ},180^{\circ},270^{\circ}$并作为输入信息，训练的目标是模型能够正确将图像分为4类（即4种旋转的角度）。

下图是自监督学习和监督学习效果的对比，可以看出自监督学习在有标签数据较少时有显著更高的性能：
![](/assets/CS-231n-14/Pasted image 20241129201730.png)

### Pretext Task: Solving "jigsaw puzzles"
这个任务是将图像的一部分裁成有一定偏移的若干部分作为输入，并打乱这些部分的相对顺序，任务目标是预测这若干部分正确的相对顺序。
![](/assets/CS-231n-14/Pasted image 20241129201926.png)

### Pretext Task: Predict Missing Pixels
显然如题，这个任务是将输入图像的一部分挖去，并让模型重新绘制被挖去的部分，并使模型的预测结果使实际尽可能相近。
![](/assets/CS-231n-14/Pasted image 20241129202101.png)
同样的，损失函数被定义为输出部分与实际部分之间的差别：
$$L_{recon}(x) = ||M\times (x - \mathcal{F}((1-M)\times x))||_2^2$$
其中M是掩码，用于指示哪些部分需要重绘（0表示缺失部分），$\mathcal{F}_{\theta}$表示参数$\theta$对应的模型函数。
实际上我们还会在总的损失函数中加上对抗损失$L_{adv}$：
$$L_{adv} = -\mathbb{E}[\log(D(x)) + \log(1-D(\mathcal{F}((1-M)\times x)))]$$
其中$D(x)$是对抗网络中的判别器，训练用于判断x是是原图还是经过修复的伪造图，前部分是最大化对真实图像的预测，后部分是最小化对伪造图像的预测。
从而我们得到一个总的损失函数：
$$L = L_{recon}(x) + L_{adv}$$
### Pretext Task: Image Coloring
任务：用灰度图像($\textbf{X}\in\mathbb{R}^{H\times W\times 1}$)预测色彩信息($\hat{\textbf{Y}}\in\mathbb{R}^{H\times W\times 2}$)，从而重建原图$[\textbf{X}|\hat{\textbf{Y}}]\in \mathbb{R}^{H\times W\times 3}$。
同时我们也可以进行双向的预测使模型能够更好地把握通道之间的相互关系，从而提高模型的性能，这也被称为Split-Brain Autoencoder：
![](/assets/CS-231n-14/Pasted image 20241129203624.png)

### Pretext Task: Video Coloring
乍一听这个任务和图像着色很类似，但实际上这并不相同，在这个任务中，我们会首先给出一张Reference Frame（如$t=0$时的图片）的完整图片（包括色彩信息），之后预测$t=1,2,3,...$时的图像颜色。
其中重点是训练模型track相同物体的能力（保持移动中的物体颜色相同），也即目标位学习reference frame和target frame在特征空间相对位置的一种映射。

形式化地讲，模型会学习Target Frame在每一次"着色"时对Reference Frame中各特征的注意力关系：
![](/assets/CS-231n-14/Pasted image 20241129204230.png)
$$\begin{aligned}
&\textbf{A}\text{为注意力矩阵}\\
&\textbf{A}_{ij} = \cfrac{\exp(f_i^Tf_j)}{\sum_k(f_k^Tf_j)}\\
&y\text{为预测的颜色}\\
&y_j = \sum_{i}\textbf{A}_{ij}c_{i}\\
&\text{损失函数定义为}\\
&L = \sum_{i}\mathcal{L}(y_i,c_i)
\end{aligned}$$

然而，实际上自监督学习具有如下的问题：
1. 设计预任务的过程很繁琐，因为要考虑到很多因素，如预任务不能太过specific等等
2. 因此学习到的特征很可能通用性并不强。

## Contrastive Representation Learning
上文提到，自监督学习得到的特征可能被特定预任务所局限，难以具有很强的通用性，那么如何使预任务更具通用性？
一种常见爱你的方法就是对比表征学习(Contrastive Representation Learning)，其主要思想就是通过学习对比不同样本间的特征，优化表征之间的距离关系，在这种情况下，我们的期望目标是相似的样本对应当靠近，而不同的样本对之间应当远离，从而我们定义：
- 正样本对(Positive Pairs)
	为了无需标注，我们一般使用同一样本的不同增强策略（即不同变换，旋转，打乱，黑白化等等）($x \& x^+$)
- 负样本对(Negative Pairs)
	指不同样本的特征对($x\& x^-$)

我们的目标是选定一个score function，并且学习一个Encoder$f(\cdot)$，使得:
$$\mathrm{score}(f(x), f(x^+))>>\mathrm{score}(f(x), f(x^-))$$
因此我们需要定义损失函数，最大化正样本对之间的score function并且最小化负样本对之间的score function，于是对于一组为$x$与$x^+,x_1^-,x_2^-,x_3^-,...x_{N-1}^-$的数据，我们定义损失函数为：
$$L=-\mathbb{E}_X[\log\cfrac{\exp(\mathcal{S}(f(x), f(x^+)))}{\exp(\mathcal{S}(f(x), f(x^+))) + \sum_i\exp(\mathcal{S}(f(x), f(x_i^-)))}]$$
可以看出，这个损失函数很类似于Softmax分类器中的Cross-Entropy损失函数，这种损失函数实际上被称为InfoNCE Loss。
为了搞清楚这种损失到底有何含义，我们介绍一个新的概念，互信息(mutual information),互信息被用于衡量两个随机变量之间的相关程度，当两个变量完全独立时，互信息为0，互信息越大，两个变量之间越相关：
$$\mathrm{MI}(x,y) = \int\int p(x,y)\log\cfrac{p(x,y)}{p(x),p(y)}\mathrm{d}x\mathrm{d}y$$
互信息的计算显然十分困难，而我们可以通过InfoNCE Loss估计两个变量互信息的下界：
$$\mathrm{MI}(x,x^+) \ge \log N - \mathcal{L}_{\text{InfoNCE}}$$
从而我们可以看出，为了使正样本对之间的互信息的下界尽可能紧，我们应当加大数据的Batch size。

### SimCLR
这是一种简单的对比表征学习网络，其中我们选用余弦相似度(Cosine Similarity)：
$$s(x,y) = \cfrac{x^Ty}{||x||\times||y||}$$
来作为Score Function。
SimCLR的网络架构如图：
![](/assets/CS-231n-14/Pasted image 20241129211200.png)
其中$\mathcal{T}$表示数据增强策略，一般来说包括：随机裁剪，随机颜色扰动，随机模糊（random cropping, random color distortion, random blur）等等，而$t\sim \mathcal{T}$表示从策略$\mathcal{T}$中选取某种数据增强方式。
$g(\cdot)$表示一个投影网络，将Encoder输出的特征投影到一个新的空间，增加一层投影网络可能有如下好处：
可以通过投影层解耦表征学习空间和投影空间。由于对比表征学习的目标是不变性，即对某一样本的各种变化具有类似的模型表现，但这也可能会导致模型在进行不变性训练后会丢失数据中的部分重要信息，尤其是数据增强等，而我们可以通过加入一层投影层讲这些影响转移到投影网络中从而使表征网络不受这些负面影响。

同时SimCLR中也可以采用mini batch-training:
首先生成N个positive pairs，组合成一个$2N\times D$的输出特征矩阵：
$$\mathbf{Z} \in \mathbb{R}^{2N\times D}=\lbrace z_1, z_2,...,z_{2N}\rbrace$$
从而我们可以计算出他们两两之间的相似度，组织成一个$2N\times 2N$的相似度矩阵:
$$\mathbf{S}_{ij} = \cfrac{z_i^Tz_j}{||z_i||\times ||z_j||}$$
其中我们只需要最大化相邻正样本对的相似度即可，如图：
![](/assets/CS-231n-14/Pasted image 20241130134835.png)

### MoCo
算法如图：
![](/assets/CS-231n-14/Pasted image 20241130134957.png)
主要思想即为了增加负样本数量，使用队列维护负样本空间，并且在每一次优化中使用输入的正样本更新队列，从而达到在不增加显存开销的情况下扩大负样本空间的效果。
此外，这种算法中还是用了动量更新法来更新负样本生成网络。
![](/assets/CS-231n-14/Pasted image 20241130135236.png)

### Sequence Contrastive Learning: Contrastive Predictive Coding
我们也可以使用序列信息来构建正负样本对，类似于预任务中的Solving "jigsaw puzzles"，对于一段给定的输入序列，我们将其与正确的接下来预测序列作为正样本对，其余作为负样本对(例如$(1,2,3,4)$与$(5,6,7,8)$就是正样本对，而与$(8,6,5,7)$就是负样本对)。
具体架构如下，我们现将输入输出的序列信息经过模型生成一组向量序列$(z_{t-3},z_{t-2},...z_t,...)$并将输入的序列信息导入类似于RNN的预测网络中进行预测，即通过$(z_{t-n}, z_{t-n+1},...,z_t)$预测$(\hat{z_{t+1}},\hat{z_{t+2}},......)$并与实际的输出做对比导出损失函数，并进行优化。
![](/assets/CS-231n-14/Pasted image 20241130140047.png)